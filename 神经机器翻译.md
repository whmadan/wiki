
# [CIPS青工委学术专栏第9期 | 神经机器翻译](http://www.cipsc.org.cn/qngw/?p=953)

## 工作流程：

* 使用一个称为编码器（Encoder）的神经网络将源语言句子编码为一个稠密向量

* 使用一个称为解码器（Decoder）的神经网络从该向量中解码出目标语言句子。上述神经网络模型一般称之为“编码器-解码器”（Encoder-Decoder）结构

![image](http://qngw2014.bj.bcebos.com/zhuankan/9/1.png)
图1. 神经机器翻译“编码器-解码器”结构

## 采用注意力机制的神经机器翻译模型

基于注意力机制的“编码器-解码器”结构采用双向循环神经网络编码器对源语言句子进行编码。解码步骤中，模型通过注意力机制选择性地关注源语言句子的不同部分，动态地构建上下文向量（见图2红色方框“编码器”部分）

![image](http://qngw2014.bj.bcebos.com/zhuankan/9/2.png)
图2. 采用注意力机制的神经机器翻译“编码器-解码器”结构

![image](http://qngw2014.bj.bcebos.com/zhuankan/9/3.png)
图3. 采用注意力机制的神经机器翻译的工作流程


## 优势：

实验表明，以BLEU值为评测指标，与传统的基于短语的统计机器翻译相比，神经机器翻译具有压倒性的优势：

* 神经机器翻译在27个语言对上超过了基于短语的统计机器翻译，仅在2个语言对上以微弱的劣势落败。

* 值得注意的是，神经机器翻译在涉及汉语的翻译任务上比短语系统能够提高4至9个BLEU点，性能提高尤其显著。

Bentivogli等人[7]对口语翻译国际研讨会（International Workshop on Spoken Language Translation，IWSLT）评测任务中英语-德语翻译任务的官方结果进行深入的人工分析和对比。他们发现，相比基于短语的机器翻译，神经机器翻译不仅在人工评测指标上占优，而且能够减少词法错误（morphology errors）、词汇错误（lexical errors）和词序错误（word order errors）。谷歌公司Wu等人[8]的实验表明在大规模语料情况下，神经机器翻译在实验所涉及的6个语言对的翻译任务上，人工评测结果仍能占优。

## 问题：

1 词语表规模受限问题

2 源语言翻译覆盖问题

3 翻译不忠实问题

## 当前研究热点

* 规模受限词语表问题
* 注意力机制问题
* 神经机器翻译和传统统计机器翻译的结合
